data(olive)
olive=olive[,-1]
summary(olive)
modFit<-train(Area~.,method="rpart",data=olive)
predict(modFit,newdata=as.data.frame(t(colMeans(olive))))
fancyRpartPlot(modFit$finalModel)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
modFit<-tree(Area~.,data=olive)
modFit<-train(Area~.,method="tree",data=olive)
?tree
library(tree)
modFit<-tree(Area~.,data=olive)
modFit
predict(modFit,newdata=as.data.frame(t(colMeans(olive))))
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit)
set.seed(13234)
?train
names(SAheart)
modFit<-train(chd~alcohol+obesity+tobacco+typea+ldl,onset=age,data=training,method="glm",family="binomial")
modFit<-train(chd~alcohol+obesity+tobacco+typea+ldl,onset=age,data=trainSA,method="glm",family="binomial")
modFit<-train(chd~.,method="glm",data=trainSA)
modFit
modFit<-train(chd~.,method="glm",data=trainSA,family="binomial")
modFit<-train(chd~.,method="glm",data=trainSA,family="binomial",onset=age)
modFit<-train(chd~.age+alcohol+obesity+tobacco+typea+ldl,method="glm",data=trainSA,family="binomial")
modFit<-train(chd~age+alcohol+obesity+tobacco+typea+ldl,method="glm",data=trainSA,family="binomial")
modFit
summary(modFit)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
predictTest<-predict(modFit,testSA)
predictTrain<-predict(modFit,trainSA)
missClass(trainSA$chd,predictTrain)
missClass(testSA$chd,predictTest)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
names(vowel.train)
vowel.train$y<-as.factor(vowel.train$y)
vowel.test$y<-as.factor(vowel.test$y)
set.seed(33833)
modFit<-train(y~.,method="rf",data=vowel.train)
?varImp
varImp(modFit)
16*28.35
3.99*1000/453.6
3.69*1000/(6*28.35)
4.49*1000/453.6
118.64+175.29+12.98+5.36+19.99
118.64+175.29+12.98+5.36+19.99+96.24+68.63+101.50+118.76+1.65
library(caret)
library(ElemeStatLearn)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
mod1 <- train(y ~ ., method="rf", data=vowel.train)
mod2 <- train(y ~ ., method="gbm", data=vowel.train)
mod1
pred1 <- predict(mod1, newdata=vowel.test)
pred2 <- predict(mod2, newdata=vowel.test)
sum(pred1==vowel.test$y) / length(vowel.test$y)
sum(pred2==vowel.test$y) / length(vowel.test$y)
predDF <- data.frame(pred1,pred2,y=vowel.test$y)
combModFit <- train(y ~ ., methpd="gam",data=predDF)
combModFit <- train(y ~ ., method="gam",data=predDF)
warnings()
combPred <- predict(combModFit,predDF)
sum(pred1==vowel.test$y & pred1==pred2) / sum(pred1==pred2)
sum(pred2==vowel.test$y & pred1==pred2) / sum(pred1==pred2)
sum(pred2==vowel.test$y & pred1==pred2) / length(vowel.test$y)
sum(pred1==vowel.test$y) / length(vowel.test$y)
sum(pred2==vowel.test$y) / length(vowel.test$y)
sum(combPred==vowel.test$y) / length(vowel.test$y)
dim(vowel.test)
vowel.test$y
combPred
combModFit
sum(pred1==vowel.test$y) / sum(pred1==pred2)
library(caret)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
model1 <- train(y ~ ., method="rf", data=vowel.train)
model2 <- train(y ~ ., method="gbm", data=vowel.train)
pred1 <- predict(model1, newdata=vowel.test)
pred2 <- predict(model2, newdata=vowel.test)
sum(pred1 == vowel.test$y)
length(vowel.test$y)
sum(pred1 == vowel.test$y) / length(vowel.test$y)
sum(pred2 == vowel.test$y)
sum(pred2 == vowel.test$y) / length(vowel.test$y)
sum(pred1 == pred2)
sum(pred1 == pred2 && pred1 == vowel.test$y)
sum(pred1 == pred2 & pred1 == vowel.test$y)
sum(pred1 == pred2)
sum(pred1 == pred2 & pred1 == vowel.test$y) / sum(pred1 == pred2)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis, predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
model1 <- train(diagnosis ~ ., method="rf", data=training)
model2 <- train(diagnosis ~ ., method="gbm", data=training)
model3 <- train(diagnosis ~ ., method="lda", data=training)
pred1 <- predict(model1, newdata=testing)
pred2 <- predict(model2, newdata=testing)
pred3 <- predict(model3, newdata=testing)
dim(testing)[1]
dim(testing)
sum(pred1 == testing$diagnosis) / length(testing$diagnosis)
sum(pred2 == testing$diagnosis) / length(testing$diagnosis)
sum(pred3 == testing$diagnosis) / length(testing$diagnosis)
predDF <- data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
combModFit <- train(diagnosis ~ ., method="rf", data=predDF)
combPred <- predict(combModFit, predDF)
sum(combPred == testing$diagnosis)
sum(combPred == testing$diagnosis) / length(testing$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
model <- train(CompressiveStrength ~ ., method="lasso", data=training)
model
?plot.enet
model$coefficients
names(model)
model$coefnames
model$cmodelInfo
model$modelInfo
plot(model,xvar="step")
model
plot(model,xvar="fraction")
names(model)
model$resample
model$finalModel
names(model)
model$control
names(model)
model$finalModel
names(training)
plot(model$finalModel,xvar="fraction")
plot(model$finalModel,xvar="penalty")
plot(model$finalModel,xvar="penalty",use.color=TRUE)
setpwd("/Users/ariane/Documents/Travail/Coursera/DataScience/")
setwd("/Users/ariane/Documents/Travail/Coursera/DataScience/")
library(lubridate)
library(lubridate)
library(lubridate)
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
?bats
library(forecast)
library(forecast)
library(forecast)
library(forecast)
library(forecast)
library(forecast)
library(forecast)
?bats
model <-bats(tstrain)
names(model)
model
forecast(model, testing)
tstest = ts(testing$visitsTumblr)
forecast(tstest)
dim(testing)
?forecast
?bats
forecast(model, tstest)
?forecast
etsl = ets(tstest, model=model)
predict(model, tstest)
forecast(model)
tstrain
tstest
dim(training)
dim(testing)
dim(dat)
year(dat$Date)
year(dat$date)
?forecast
forecast(model)
forecast(model, h=235)
forecast(model, h=235)$Forecast
names(forecast(model, h=235))
forecast(model, h=235)$fitted
pred <- forecast(model, h=235)
typeof(pred)
pred[[1]]
pred[[2]]
pred[[2]]$Data
pred[[2]].Data
typeof(pred[[2]])
pred[[2]] == tstest
pred[[2]] == testing
dim(testing)
names(testing)
pred[[2]] == testing$visitsTumblr
pred[[2]]
testing$visitsTumblr
pred2
pred
pred2[[6]]
pred[[6]]
pred[1:10]
pred$lower
pred$lower[,2]
pred$lower[,2] < testing$visitsTumblr & pred$upper[,2] > testing$visitsTumblr
sum(pred$lower[,2] < testing$visitsTumblr & pred$upper[,2] > testing$visitsTumblr) / length(testing$visitsTumblr)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
model <- svm(concrete[,-CompressiveStrength], concrete$CompressiveStrength)
names(concrete)
model <- svm(concrete[,-c(9)], concrete$CompressiveStrength)
model
pred <- predict(model, testing)
pred <- predict(model, testing[,-c(9)])
pred
length(pred)
sqrt(sum((testing$CompressiveStrength - pred)^2)/256)
sum((testing$CompressiveStrength - pred)^2)
8157.916/256
sqrt(31.86686)
